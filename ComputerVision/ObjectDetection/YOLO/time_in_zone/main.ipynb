{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python\\EveryDayCoding\\ComputerVision\\ObjectDetection\\YOLO\\Quantize\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "from ultralytics.yolo.utils.ops import non_max_suppression, scale_boxes\n",
    "from ultralytics.yolo.data.dataloaders.stream_loaders import LoadImages, LoadStreams\n",
    "from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "\n",
    "# model config\n",
    "half = False\n",
    "img_sz = [320, 320]\n",
    "device = 'cpu'\n",
    "classes = list(range(80))\n",
    "conf_thres = 0.5\n",
    "iou_thres = 0.5\n",
    "max_det = 1000\n",
    "line_thickness = 2\n",
    "agnostic_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "import onnxruntime\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.75  Python-3.11.8 torch-2.2.2+cpu CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  3.9s, saved as yolov8n.onnx (12.2 MB)\n",
      "\n",
      "Export complete (15.0s)\n",
      "Results saved to \u001b[1mF:\\python\\EveryDayCoding\\ComputerVision\\ObjectDetection\\YOLO\\Quantize\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640 \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics YOLOv8.0.75  Python-3.11.8 torch-2.2.2+cpu CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.4s, saved as yolov8n.onnx (12.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv8 requirement \"openvino-dev>=2022.3\" not found, attempting AutoUpdate...\n",
      "Collecting openvino-dev>=2022.3\n",
      "  Downloading openvino_dev-2024.0.0-14509-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting defusedxml>=0.7.1 (from openvino-dev>=2022.3)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting networkx<=3.1.0 (from openvino-dev>=2022.3)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from openvino-dev>=2022.3) (1.26.4)\n",
      "Collecting openvino-telemetry>=2023.2.1 (from openvino-dev>=2022.3)\n",
      "  Downloading openvino_telemetry-2024.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: packaging in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from openvino-dev>=2022.3) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from openvino-dev>=2022.3) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.25.1 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from openvino-dev>=2022.3) (2.31.0)\n",
      "Collecting openvino==2024.0.0 (from openvino-dev>=2022.3)\n",
      "  Downloading openvino-2024.0.0-14509-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\python\\everydaycoding\\computervision\\objectdetection\\yolo\\quantize\\.venv\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2022.3) (2024.2.2)\n",
      "Downloading openvino_dev-2024.0.0-14509-py3-none-any.whl (4.7 MB)\n",
      "   ---------------------------------------- 4.7/4.7 MB 2.7 MB/s eta 0:00:0005\n",
      "Downloading openvino-2024.0.0-14509-cp311-cp311-win_amd64.whl (31.8 MB)\n",
      "   ---------------------------------------- 31.8/31.8 MB 5.2 MB/s eta 0:00:00\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading openvino_telemetry-2024.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: openvino-telemetry, openvino, networkx, defusedxml, openvino-dev\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.3\n",
      "    Uninstalling networkx-3.3:\n",
      "      Successfully uninstalled networkx-3.3\n",
      "Successfully installed defusedxml-0.7.1 networkx-3.1 openvino-2024.0.0 openvino-dev-2024.0.0 openvino-telemetry-2024.1.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['openvino-dev>=2022.3']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.0.0-14509-34caeefd078-releases/2024/0...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  65.9s, saved as yolov8n_openvino_model\\ (12.3 MB)\n",
      "\n",
      "Export complete (68.0s)\n",
      "Results saved to \u001b[1mF:\\python\\EveryDayCoding\\ComputerVision\\ObjectDetection\\YOLO\\Quantize\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n_openvino_model imgsz=640 \n",
      "Validate:        yolo val task=detect model=yolov8n_openvino_model imgsz=640 data=coco.yaml \n",
      "Visualize:       https://netron.app\n",
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n",
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format='onnx')  # creates 'yolov8n.onnx'\n",
    "model.export(format='openvino')  # creates 'yolov8n_openvino_model/'\n",
    "\n",
    "# Load the exported OpenVINO model\n",
    "ov_model = YOLO('yolov8n_openvino_model/')\n",
    "\n",
    "# Load the exported ONNX model\n",
    "onnx_model = YOLO('yolov8n.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess  = onnxruntime.InferenceSession('yolov8n.onnx', providers=onnxruntime.get_available_providers())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './Video/demo.mp4'\n",
    "# model = YOLO('yolov8n.onnx', task='detect')\n",
    "# model = YOLO('yolov8n.pt', task='detect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.half = True\n",
    "model.imgsz=[640,640]\n",
    "model.int8 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading yolov8n_openvino_model for OpenVINO inference...\n",
      "\n",
      "0: 640x640 3 persons, 134.7ms\n",
      "Speed: 13.9ms preprocess, 134.7ms inference, 332.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 133.5ms\n",
      "Speed: 0.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 130.0ms\n",
      "Speed: 5.6ms preprocess, 130.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 135.3ms\n",
      "Speed: 3.0ms preprocess, 135.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 persons, 167.6ms\n",
      "Speed: 11.6ms preprocess, 167.6ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 persons, 132.7ms\n",
      "Speed: 12.5ms preprocess, 132.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 159.0ms\n",
      "Speed: 4.0ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 132.2ms\n",
      "Speed: 4.0ms preprocess, 132.2ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 134.1ms\n",
      "Speed: 3.6ms preprocess, 134.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 123.4ms\n",
      "Speed: 3.7ms preprocess, 123.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 127.0ms\n",
      "Speed: 2.3ms preprocess, 127.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 121.2ms\n",
      "Speed: 4.5ms preprocess, 121.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 135.5ms\n",
      "Speed: 0.0ms preprocess, 135.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 116.4ms\n",
      "Speed: 4.0ms preprocess, 116.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 191.0ms\n",
      "Speed: 2.0ms preprocess, 191.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 136.6ms\n",
      "Speed: 0.0ms preprocess, 136.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 127.8ms\n",
      "Speed: 0.0ms preprocess, 127.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 118.6ms\n",
      "Speed: 1.7ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 120.7ms\n",
      "Speed: 8.3ms preprocess, 120.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 120.4ms\n",
      "Speed: 0.0ms preprocess, 120.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 107.2ms\n",
      "Speed: 9.5ms preprocess, 107.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 120.3ms\n",
      "Speed: 3.9ms preprocess, 120.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 115.6ms\n",
      "Speed: 17.1ms preprocess, 115.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 173.3ms\n",
      "Speed: 3.0ms preprocess, 173.3ms inference, 13.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 110.2ms\n",
      "Speed: 8.3ms preprocess, 110.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 135.7ms\n",
      "Speed: 0.0ms preprocess, 135.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 106.5ms\n",
      "Speed: 0.9ms preprocess, 106.5ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 155.4ms\n",
      "Speed: 17.7ms preprocess, 155.4ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 117.6ms\n",
      "Speed: 0.0ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 112.1ms\n",
      "Speed: 0.0ms preprocess, 112.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 118.0ms\n",
      "Speed: 0.0ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 118.2ms\n",
      "Speed: 0.0ms preprocess, 118.2ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 117.6ms\n",
      "Speed: 0.0ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 122.7ms\n",
      "Speed: 0.0ms preprocess, 122.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 117.0ms\n",
      "Speed: 0.0ms preprocess, 117.0ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 113.4ms\n",
      "Speed: 0.0ms preprocess, 113.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 118.0ms\n",
      "Speed: 0.0ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 120.7ms\n",
      "Speed: 17.7ms preprocess, 120.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 107.8ms\n",
      "Speed: 3.0ms preprocess, 107.8ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 120.7ms\n",
      "Speed: 0.0ms preprocess, 120.7ms inference, 12.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 125.5ms\n",
      "Speed: 0.0ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 113.1ms\n",
      "Speed: 4.4ms preprocess, 113.1ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 112.8ms\n",
      "Speed: 16.3ms preprocess, 112.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 120.4ms\n",
      "Speed: 0.0ms preprocess, 120.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 123.5ms\n",
      "Speed: 0.0ms preprocess, 123.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 126.9ms\n",
      "Speed: 3.4ms preprocess, 126.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 112.2ms\n",
      "Speed: 0.0ms preprocess, 112.2ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 113.4ms\n",
      "Speed: 16.6ms preprocess, 113.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 120.4ms\n",
      "Speed: 0.0ms preprocess, 120.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 120.0ms\n",
      "Speed: 0.0ms preprocess, 120.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 124.1ms\n",
      "Speed: 15.7ms preprocess, 124.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 141.0ms\n",
      "Speed: 0.0ms preprocess, 141.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 129.9ms\n",
      "Speed: 0.0ms preprocess, 129.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 154.3ms\n",
      "Speed: 19.5ms preprocess, 154.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 141.0ms\n",
      "Speed: 0.0ms preprocess, 141.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 147.6ms\n",
      "Speed: 15.6ms preprocess, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 139.4ms\n",
      "Speed: 2.6ms preprocess, 139.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 124.5ms\n",
      "Speed: 0.3ms preprocess, 124.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 113.5ms\n",
      "Speed: 0.0ms preprocess, 113.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 116.3ms\n",
      "Speed: 4.4ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 106.6ms\n",
      "Speed: 13.3ms preprocess, 106.6ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 124.5ms\n",
      "Speed: 0.0ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 1 parking meter, 117.8ms\n",
      "Speed: 16.9ms preprocess, 117.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 117.6ms\n",
      "Speed: 0.0ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 117.7ms\n",
      "Speed: 0.0ms preprocess, 117.7ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 124.0ms\n",
      "Speed: 12.9ms preprocess, 124.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 122.6ms\n",
      "Speed: 0.0ms preprocess, 122.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 124.9ms\n",
      "Speed: 0.0ms preprocess, 124.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 114.0ms\n",
      "Speed: 17.0ms preprocess, 114.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 124.2ms\n",
      "Speed: 1.2ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 119.9ms\n",
      "Speed: 0.0ms preprocess, 119.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 125.6ms\n",
      "Speed: 16.7ms preprocess, 125.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 147.7ms\n",
      "Speed: 5.1ms preprocess, 147.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 120.8ms\n",
      "Speed: 0.0ms preprocess, 120.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 120.8ms\n",
      "Speed: 0.0ms preprocess, 120.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 132.3ms\n",
      "Speed: 0.0ms preprocess, 132.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 166.2ms\n",
      "Speed: 0.0ms preprocess, 166.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 129.4ms\n",
      "Speed: 0.0ms preprocess, 129.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 112.2ms\n",
      "Speed: 4.0ms preprocess, 112.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 131.3ms\n",
      "Speed: 2.9ms preprocess, 131.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 123.1ms\n",
      "Speed: 3.0ms preprocess, 123.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 139.8ms\n",
      "Speed: 0.0ms preprocess, 139.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 118.6ms\n",
      "Speed: 3.0ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 107.6ms\n",
      "Speed: 4.0ms preprocess, 107.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 117.1ms\n",
      "Speed: 14.4ms preprocess, 117.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 136.1ms\n",
      "Speed: 0.0ms preprocess, 136.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 145.3ms\n",
      "Speed: 0.0ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 117.7ms\n",
      "Speed: 15.6ms preprocess, 117.7ms inference, 16.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 132.9ms\n",
      "Speed: 0.0ms preprocess, 132.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 113.4ms\n",
      "Speed: 2.4ms preprocess, 113.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 116.7ms\n",
      "Speed: 2.1ms preprocess, 116.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 121.2ms\n",
      "Speed: 3.0ms preprocess, 121.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 125.2ms\n",
      "Speed: 2.6ms preprocess, 125.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 113.1ms\n",
      "Speed: 4.0ms preprocess, 113.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 130.6ms\n",
      "Speed: 0.0ms preprocess, 130.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 116.6ms\n",
      "Speed: 1.2ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 115.3ms\n",
      "Speed: 0.0ms preprocess, 115.3ms inference, 11.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 131.3ms\n",
      "Speed: 35.4ms preprocess, 131.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 117.1ms\n",
      "Speed: 1.1ms preprocess, 117.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 117.6ms\n",
      "Speed: 3.8ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 111.4ms\n",
      "Speed: 3.0ms preprocess, 111.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 113.7ms\n",
      "Speed: 3.0ms preprocess, 113.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 133.6ms\n",
      "Speed: 0.0ms preprocess, 133.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 112.2ms\n",
      "Speed: 3.0ms preprocess, 112.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 132.7ms\n",
      "Speed: 0.0ms preprocess, 132.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 115.8ms\n",
      "Speed: 0.0ms preprocess, 115.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 116.6ms\n",
      "Speed: 1.3ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 120.5ms\n",
      "Speed: 3.0ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 116.5ms\n",
      "Speed: 2.3ms preprocess, 116.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 128.4ms\n",
      "Speed: 3.0ms preprocess, 128.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 115.4ms\n",
      "Speed: 18.4ms preprocess, 115.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 112.3ms\n",
      "Speed: 4.0ms preprocess, 112.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 126.7ms\n",
      "Speed: 2.5ms preprocess, 126.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 133.4ms\n",
      "Speed: 0.0ms preprocess, 133.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 115.7ms\n",
      "Speed: 0.0ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 112.9ms\n",
      "Speed: 3.9ms preprocess, 112.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 110.8ms\n",
      "Speed: 0.0ms preprocess, 110.8ms inference, 16.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 116.5ms\n",
      "Speed: 0.0ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 113.0ms\n",
      "Speed: 3.0ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 122.6ms\n",
      "Speed: 4.1ms preprocess, 122.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(source)\n",
    "# used to record the time when we processed last frame \n",
    "prev_frame_time = 0\n",
    "  \n",
    "# used to record the time at which we processed current frame \n",
    "new_frame_time = 0\n",
    "# capture.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "# capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)\n",
    "\n",
    "while (capture.isOpened()):\n",
    "    ret, frame = capture.read() \n",
    "    frame = cv2.resize(frame, (640, 640))\n",
    "    results = ov_model(frame)[0]\n",
    "    \n",
    "    if ret == True: \n",
    "        for box in results.boxes:\n",
    "            class_name = results.names[box.cls[0].item()] # Class name\n",
    "            cords = box.xyxy[0].tolist()\n",
    "            x1, y1, x2, y2 = (round(x) for x in cords)\n",
    "            x, y, w, h = x1, y1, x2 - x1, y2 - y1    \n",
    "            # confidence = round(box.conf[0].item(), 2)\n",
    "            # print(confidence)\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            \n",
    "        new_frame_time = time.time() \n",
    "        fps = 1/(new_frame_time-prev_frame_time) \n",
    "        prev_frame_time = new_frame_time \n",
    "        fps = int(fps) \n",
    "        fps = str(fps)\n",
    "        cv2.putText(frame, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX , 3, (100, 255, 0), 3, cv2.LINE_AA) \n",
    "        cv2.imshow('Frame', frame) \n",
    "        \n",
    "        if cv2.waitKey(25) in (ord('q'), ord('Q')):\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "  \n",
    "# After the loop release the capture object \n",
    "capture.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

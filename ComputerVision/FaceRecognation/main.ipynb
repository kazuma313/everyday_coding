{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 1152, 3)\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(\"foto.JPG\")\n",
    "print(image.shape)\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(204, 491, 247, 448),\n",
       " (257, 919, 308, 867),\n",
       " (233, 765, 276, 722),\n",
       " (198, 163, 260, 100),\n",
       " (218, 601, 254, 565),\n",
       " (223, 847, 266, 804),\n",
       " (205, 337, 257, 285),\n",
       " (170, 733, 206, 697),\n",
       " (250, 1057, 286, 1021)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"foto.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    " \n",
    "cv2.imshow(\"image\", image) \n",
    "  \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[(150, 408, 305, 253)]\n",
      "[(139, 428, 325, 242)]\n",
      "[(142, 464, 365, 241)]\n",
      "[(142, 489, 365, 266)]\n",
      "[(142, 489, 365, 266)]\n",
      "[(142, 489, 365, 266)]\n",
      "[(142, 489, 365, 266)]\n",
      "[(142, 489, 365, 266)]\n",
      "[(142, 489, 365, 266)]\n",
      "[(160, 489, 345, 304)]\n",
      "[]\n",
      "[(142, 489, 365, 266)]\n",
      "[(139, 469, 325, 283)]\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(3, 512)\n",
    "capture.set(4, 512)\n",
    "\n",
    "while (capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    print(face_locations)\n",
    "    if ret == True:\n",
    "\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        if cv2.waitKey(25) in (ord('q'), ord('Q')):\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "    \n",
    "    cv2.imshow('Frame', frame) \n",
    "\n",
    "capture.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attandance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\".\\Resources\\background.png\")\n",
    "cv2.imshow(\"image\", image) \n",
    "  \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cvzone\n",
    "from firebase_admin import db\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import storage\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "    firebase_admin.initialize_app(cred,{\n",
    "        'databaseURL': 'https://attandance-66c54-default-rtdb.asia-southeast1.firebasedatabase.app/',\n",
    "        'storageBucket': 'attandance-66c54.appspot.com'\n",
    "})\n",
    "bucket = storage.bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perlu ditambahkan jika tidak terdeteksi muka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading encoded file\n",
      "encoded file collected\n"
     ]
    }
   ],
   "source": [
    "img_background =  cv2.imread(r\".\\Resources\\background.png\")\n",
    "img_background = cv2.resize(img_background, (1280, 512), fx=1, fy=1)\n",
    "\n",
    "folder_mode_path = r\".\\Resources\\Modes\"\n",
    "mode_path_list = os.listdir(folder_mode_path)\n",
    "img_mode_list = []\n",
    "\n",
    "print(\"loading encoded file\")\n",
    "file_encode = open(r\".\\model\\Encode\\my_EncodeFile.p\", \"rb\")\n",
    "encodeListKnown = pickle.load(file_encode)\n",
    "file_encode.close()\n",
    "encoded_img_list, id_list = encodeListKnown\n",
    "\n",
    "print(\"encoded file collected\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "\n",
    "# get images mode and resize them\n",
    "for path in mode_path_list:\n",
    "    img_mode = cv2.imread(os.path.join(folder_mode_path, path))\n",
    "    img_mode = cv2.resize(img_mode, (430, 480), fx=1, fy=1)\n",
    "    img_mode_list.append(img_mode)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 128)\n",
    "cap.set(4, 128)\n",
    "\n",
    "while True:\n",
    "    succes, img = cap.read()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    encode_frames = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    for encode_frame, face_loc in zip(encode_frames, face_locations):\n",
    "        # check the matches face encoded\n",
    "        matches = face_recognition.compare_faces(encoded_img_list, encode_frame)\n",
    "        # magnitude of the distance similarity\n",
    "        face_distance = face_recognition.face_distance(encoded_img_list, encode_frame)\n",
    "        \n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        if matches[best_match_index]:\n",
    "            person_id = id_list[best_match_index]\n",
    "            \n",
    "            # cvzone.putTextRect(\n",
    "            #         img, f\"Face Detected, person id : {person_id[0]}\", (20, 100),\n",
    "            #         scale=1, thickness=1, \n",
    "            #         colorT=(0, 0, 255), colorR=(255, 100, 0), \n",
    "            #         font=cv2.FONT_HERSHEY_PLAIN, \n",
    "            #         offset=1,  \n",
    "            #         border=1, colorB=(0, 5, 0)\n",
    "            #     )\n",
    "\n",
    "        \n",
    "            for top, right, bottom, left in face_locations:\n",
    "                # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "                top -= 60\n",
    "                right += 20\n",
    "                bottom += 60\n",
    "                left -= 20\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(img, \n",
    "                              (left, top), \n",
    "                              (right, bottom), \n",
    "                              (0, 0, 255), \n",
    "                              2)\n",
    "\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(img, \n",
    "                              (left, bottom - 35), \n",
    "                              (right, bottom), \n",
    "                              (0, 0, 255), \n",
    "                              cv2.FILLED)\n",
    "                \n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(img, f\" {person_id[0]}: {person_id[1]}\", (left + 2, bottom - 2), font, 1.0, (255, 255, 255), 1)\n",
    "            \n",
    "            id = id_list[best_match_index]\n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "                modeType = 1\n",
    "\n",
    "        img_background[100:100+img.shape[0], 50:50+img.shape[1], :] = img\n",
    "        img_background[20:20+img_mode_list[modeType].shape[0], 800:800+img_mode_list[modeType].shape[1], :] = img_mode_list[modeType]    \n",
    "        \n",
    "        if counter != 0:\n",
    "            if counter == 1:\n",
    "                person_info = db.reference(f\"people/{id[0]}\").get()\n",
    "                blob = bucket.get_blob(f\"images/{id[0]}_{id[1]}.JPG\")\n",
    "                array = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "                img_person = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "                img_person = cv2.resize(img_person, (230, 240), fx=1, fy=1)\n",
    "\n",
    "                datetimeObject = datetime.strptime(person_info['last_attandance'],\"%Y-%m-%d %H:%M:%S\")\n",
    "                secondsElapsed = (datetime.now()-datetimeObject).total_seconds()\n",
    "                if secondsElapsed > 60:\n",
    "                    ref = db.reference(f\"people/{id[0]}\")\n",
    "                    person_info['total_attandance'] += 1\n",
    "                    ref.child('total_attandance').set(person_info['total_attandance'])\n",
    "                    ref.child('last_attandance').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                else:\n",
    "                    modeType = 3\n",
    "                    counter = 0\n",
    "                    img_background[20:20+img_mode_list[modeType].shape[0], 800:800+img_mode_list[modeType].shape[1], :] = img_mode_list[modeType]    \n",
    "                    \n",
    "            if modeType != 3:\n",
    "                \n",
    "                if 10<counter<20:\n",
    "                    modeType = 2\n",
    "                    \n",
    "                img_background[20:20+img_mode_list[modeType].shape[0], 800:800+img_mode_list[modeType].shape[1], :] = img_mode_list[modeType]    \n",
    "                    \n",
    "                if counter <=10:\n",
    "                    cv2.putText(img_background, \n",
    "                                str(person_info['total_attandance']), \n",
    "                                (840, 80),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                0.5, \n",
    "                                (100, 100, 100), \n",
    "                                1)\n",
    "                    cv2.putText(img_background, \n",
    "                                str(id[0]), \n",
    "                                (1000, 360), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                0.5, \n",
    "                                (100, 100, 100), \n",
    "                                1)\n",
    "                    cv2.putText(img_background, \n",
    "                                str(person_info['major']), \n",
    "                                (1000, 403), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                0.5, \n",
    "                                (100, 100, 100), \n",
    "                                1)\n",
    "                    cv2.putText(img_background, \n",
    "                                str(person_info['starting_year']), \n",
    "                                (1110, 463), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                0.5, \n",
    "                                (100, 100, 100), \n",
    "                                1)\n",
    "                    \n",
    "                    (w, h), _ = cv2.getTextSize(person_info['name'], cv2.FONT_HERSHEY_SIMPLEX, 1, 1)\n",
    "                    offset = (430 - w) // 2\n",
    "                    cv2.putText(img_background, \n",
    "                                str(person_info['name']), \n",
    "                                (840 + offset, 320), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                0.5, \n",
    "                                (100, 100, 100), \n",
    "                                1)\n",
    "                    \n",
    "                    img_background[50:50+img_person.shape[0], 900:900+img_person.shape[1]]= img_person\n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "                if counter >=20:\n",
    "                    counter = 0\n",
    "                    modeType = 0\n",
    "                    person_info = []\n",
    "                    img_person = []\n",
    "                    img_background[20:20+img_mode_list[modeType].shape[0], 800:800+img_mode_list[modeType].shape[1], :] = img_mode_list[modeType]  \n",
    "            \n",
    "    cv2.imshow(\"image Background\", img_background)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
